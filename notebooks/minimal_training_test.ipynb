{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441e3834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Working from: /Users/jamesliu/Documents/GitHub/skyguard\n",
      "üêç Python: 3.13.2 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 12:55:35) [Clang 14.0.6 ]\n",
      "‚úÖ MPS (Metal) available\n",
      "üíæ System info complete\n"
     ]
    }
   ],
   "source": [
    "# Ultra-Minimal Training Test for M2 MacBook Air (8GB RAM)\n",
    "# File: notebooks/minimal_training_test.ipynb\n",
    "# Run each cell individually to test step by step\n",
    "\n",
    "# CELL 1: Environment Setup and Path Configuration\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Set working directory to project root\n",
    "project_root = Path.cwd()\n",
    "if project_root.name == 'notebooks':\n",
    "    project_root = project_root.parent\n",
    "    os.chdir(project_root)\n",
    "\n",
    "print(f\"üîç Working from: {project_root}\")\n",
    "print(f\"üêç Python: {sys.version}\")\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Check memory\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"‚úÖ MPS (Metal) available\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Using CPU only\")\n",
    "\n",
    "print(f\"üíæ System info complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1544b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING ULTRA-LIGHT ENVIRONMENT\n",
      "==================================================\n",
      "‚úÖ Ultralytics imported successfully\n",
      "üì¶ Testing minimal model loading...\n",
      "‚úÖ YOLOv11n loaded successfully\n",
      "üóëÔ∏è Model cleared from memory\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Ultra-Light Environment Test\n",
    "print(\"üß™ TESTING ULTRA-LIGHT ENVIRONMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Force garbage collection to free memory\n",
    "gc.collect()\n",
    "\n",
    "try:\n",
    "    # Test basic imports with minimal memory\n",
    "    from ultralytics import YOLO\n",
    "    print(\"‚úÖ Ultralytics imported successfully\")\n",
    "    \n",
    "    # Test model loading with minimal overhead\n",
    "    print(\"üì¶ Testing minimal model loading...\")\n",
    "    model = YOLO('yolo11n.pt')  # This might download if not cached\n",
    "    print(\"‚úÖ YOLOv11n loaded successfully\")\n",
    "    \n",
    "    # Clear model from memory immediately\n",
    "    del model\n",
    "    gc.collect()\n",
    "    print(\"üóëÔ∏è Model cleared from memory\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Basic test failed: {e}\")\n",
    "    print(\"üí° Try: pip install ultralytics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f4131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç MINIMAL DATASET CHECK\n",
      "==================================================\n",
      "‚úÖ Found processed dataset: /Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo\n",
      "   üì∏ train: 6471 images\n",
      "   üì∏ val: 548 images\n",
      "   üì∏ test: 1610 images\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Minimal Dataset Validation\n",
    "print(\"\\nüîç MINIMAL DATASET CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if our converted data exists\n",
    "processed_path = project_root / \"data\" / \"processed\" / \"vision\" / \"visdrone_yolo\"\n",
    "dataset_yaml = processed_path / \"dataset.yaml\"\n",
    "\n",
    "if dataset_yaml.exists():\n",
    "    print(f\"‚úÖ Found processed dataset: {processed_path}\")\n",
    "    \n",
    "    # Count images in each split\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        img_dir = processed_path / \"images\" / split\n",
    "        if img_dir.exists():\n",
    "            count = len(list(img_dir.glob(\"*.jpg\")))\n",
    "            print(f\"   üì∏ {split}: {count} images\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {split}: Missing\")\n",
    "else:\n",
    "    print(f\"‚ùå No processed dataset found\")\n",
    "    print(\"üí° Need to run data conversion first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85052033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° ULTRA-MINIMAL SETTINGS TEST\n",
      "==================================================\n",
      "üîß Ultra-minimal settings:\n",
      "   ‚Ä¢ epochs: 1\n",
      "   ‚Ä¢ imgsz: 160\n",
      "   ‚Ä¢ batch: 1\n",
      "   ‚Ä¢ device: cpu\n",
      "   ‚Ä¢ workers: 1\n",
      "   ‚Ä¢ patience: 50\n",
      "   ‚Ä¢ save: False\n",
      "   ‚Ä¢ plots: False\n",
      "   ‚Ä¢ verbose: False\n",
      "   ‚Ä¢ cache: False\n",
      "   ‚Ä¢ close_mosaic: 0\n",
      "\n",
      "üí° These settings use:\n",
      "   ‚Ä¢ 160px images (vs 640px normal)\n",
      "   ‚Ä¢ Batch size 1 (vs 16 normal)\n",
      "   ‚Ä¢ CPU only (vs GPU)\n",
      "   ‚Ä¢ No augmentation or caching\n",
      "   ‚Ä¢ Minimal memory footprint\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Ultra-Minimal Training Settings Test\n",
    "print(\"\\n‚ö° ULTRA-MINIMAL SETTINGS TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# These are the most minimal settings possible for M2 8GB\n",
    "ultra_minimal_settings = {\n",
    "    'epochs': 1,           # Just 1 epoch\n",
    "    'imgsz': 160,          # Tiny images (1/4 of normal)\n",
    "    'batch': 1,            # Single image at a time\n",
    "    'device': 'cpu',       # Force CPU (more stable on M2)\n",
    "    'workers': 1,          # Single worker thread\n",
    "    'patience': 50,        # No early stopping\n",
    "    'save': False,         # Don't save intermediate checkpoints\n",
    "    'plots': False,        # No plots to save memory\n",
    "    'verbose': False,      # Minimal output\n",
    "    'cache': False,        # Don't cache images\n",
    "    'close_mosaic': 0,     # Disable mosaic augmentation\n",
    "}\n",
    "\n",
    "print(\"üîß Ultra-minimal settings:\")\n",
    "for key, value in ultra_minimal_settings.items():\n",
    "    print(f\"   ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "print(\"\\nüí° These settings use:\")\n",
    "print(\"   ‚Ä¢ 160px images (vs 640px normal)\")\n",
    "print(\"   ‚Ä¢ Batch size 1 (vs 16 normal)\")\n",
    "print(\"   ‚Ä¢ CPU only (vs GPU)\")\n",
    "print(\"   ‚Ä¢ No augmentation or caching\")\n",
    "print(\"   ‚Ä¢ Minimal memory footprint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2e0693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† MEMORY-CONSCIOUS MODEL TEST\n",
      "==================================================\n",
      "üì¶ Loading YOLOv11n with minimal memory...\n",
      "üñºÔ∏è Testing prediction on: 0000271_01401_d_0000380.jpg\n",
      "‚úÖ Prediction successful!\n",
      "   üìä Found 0 detections\n",
      "üóëÔ∏è Model cleaned from memory\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Memory-Conscious Model Test\n",
    "print(\"\\nüß† MEMORY-CONSCIOUS MODEL TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Clear any existing memory\n",
    "    gc.collect()\n",
    "    \n",
    "    # Load model with minimal settings\n",
    "    print(\"üì¶ Loading YOLOv11n with minimal memory...\")\n",
    "    model = YOLO('yolo11n.pt')\n",
    "    \n",
    "    # Test prediction on a single small image to verify it works\n",
    "    test_img_dir = project_root / \"data\" / \"raw\" / \"vision\" / \"visdrone\" / \"VisDrone2019-DET-val\" / \"images\"\n",
    "    \n",
    "    if test_img_dir.exists():\n",
    "        test_images = list(test_img_dir.glob(\"*.jpg\"))\n",
    "        if test_images:\n",
    "            print(f\"üñºÔ∏è Testing prediction on: {test_images[0].name}\")\n",
    "            \n",
    "            # Single prediction with minimal settings\n",
    "            results = model.predict(\n",
    "                source=str(test_images[0]),\n",
    "                imgsz=160,          # Very small\n",
    "                conf=0.5,           # Higher confidence to reduce detections\n",
    "                device='cpu',       # Force CPU\n",
    "                verbose=False,      # Quiet\n",
    "                save=False,         # Don't save\n",
    "                show=False          # Don't display\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Prediction successful!\")\n",
    "            print(f\"   üìä Found {len(results[0].boxes)} detections\")\n",
    "            \n",
    "            # Clean up immediately\n",
    "            del results\n",
    "        else:\n",
    "            print(\"‚ùå No test images found\")\n",
    "    else:\n",
    "        print(\"‚ùå Test image directory not found\")\n",
    "    \n",
    "    # Clean up model\n",
    "    del model\n",
    "    gc.collect()\n",
    "    print(\"üóëÔ∏è Model cleaned from memory\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db90471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨ MICRO-TRAINING TEST\n",
      "==================================================\n",
      "‚ö†Ô∏è WARNING: This will attempt actual training\n",
      "üí° Expected time: 2-5 minutes on M2 Air\n",
      "üìÅ Using processed dataset: /Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/dataset.yaml\n",
      "üöÄ Starting micro-training...\n",
      "üìä Progress will be minimal to save memory\n",
      "Ultralytics 8.3.147 üöÄ Python-3.13.2 torch-2.7.0 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=0, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=160, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=micro_test, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=/Users/jamesliu/Documents/GitHub/skyguard/runs/detect, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/Users/jamesliu/Documents/GitHub/skyguard/runs/detect/micro_test, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    432622  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,591,790 parameters, 2,591,774 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.1 ms, read: 721.5¬±223.6 MB/s, size: 261.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/labels/train.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6471/6471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/images/train/0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/images/train/0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/images/train/9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/images/train/9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.0 ms, read: 407.7¬±80.8 MB/s, size: 131.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/jamesliu/Documents/GitHub/skyguard/data/processed/vision/visdrone_yolo/labels/val.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 548/548 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 160 train, 160 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/jamesliu/Documents/GitHub/skyguard/runs/detect/micro_test\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        1/1         0G      3.383      3.152      1.004         50        160: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6471/6471 [11:25<00:00,  9.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [00:13<00:00, 20.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.443     0.0203     0.0164    0.00613\n",
      "\n",
      "1 epochs completed in 0.195 hours.\n",
      "Optimizer stripped from /Users/jamesliu/Documents/GitHub/skyguard/runs/detect/micro_test/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from /Users/jamesliu/Documents/GitHub/skyguard/runs/detect/micro_test/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating /Users/jamesliu/Documents/GitHub/skyguard/runs/detect/micro_test/weights/best.pt...\n",
      "Ultralytics 8.3.147 üöÄ Python-3.13.2 torch-2.7.0 CPU (Apple M2)\n",
      "YOLO11n summary (fused): 100 layers, 2,584,102 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:13<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.443     0.0203     0.0164    0.00613\n",
      "            pedestrian        520       8844     0.0189   0.000113    0.00356   0.000982\n",
      "                people        482       5125          1          0    0.00224   0.000535\n",
      "               bicycle        364       1287          1          0          0          0\n",
      "                   car        515      14064      0.323      0.136      0.125     0.0474\n",
      "                   van        421       1975     0.0627      0.043      0.014    0.00512\n",
      "                 truck        266        750      0.018     0.0198    0.00721    0.00255\n",
      "              tricycle        337       1045          1          0    0.00388    0.00164\n",
      "       awning-tricycle        220        532          1          0    0.00165   0.000823\n",
      "                   bus        131        251    0.00472    0.00398    0.00178   0.000798\n",
      "                 motor        485       4886          0          0    0.00536    0.00146\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "üéâ Micro-training completed!\n",
      "‚úÖ Your setup works for training!\n",
      "üìä mAP@0.5: 0.016\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Micro-Training Test (Run this only if above cells work)\n",
    "print(\"\\nüî¨ MICRO-TRAINING TEST\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚ö†Ô∏è WARNING: This will attempt actual training\")\n",
    "print(\"üí° Expected time: 2-5 minutes on M2 Air\")\n",
    "\n",
    "# Only proceed if user confirms\n",
    "proceed = input(\"Proceed with micro-training? (y/n): \").lower().strip() == 'y'\n",
    "\n",
    "if proceed:\n",
    "    try:\n",
    "        gc.collect()  # Clear memory first\n",
    "        \n",
    "        # Load model\n",
    "        model = YOLO('yolo11n.pt')\n",
    "        \n",
    "        # Check if we have processed data, otherwise use VisDrone.yaml\n",
    "        if dataset_yaml.exists():\n",
    "            data_path = str(dataset_yaml)\n",
    "            print(f\"üìÅ Using processed dataset: {data_path}\")\n",
    "        else:\n",
    "            data_path = \"VisDrone.yaml\"\n",
    "            print(f\"üìÅ Using VisDrone.yaml (will auto-download)\")\n",
    "        \n",
    "        print(\"üöÄ Starting micro-training...\")\n",
    "        print(\"üìä Progress will be minimal to save memory\")\n",
    "        \n",
    "        # Ultra-minimal training\n",
    "        results = model.train(\n",
    "            data=data_path,\n",
    "            epochs=1,\n",
    "            imgsz=160,\n",
    "            batch=1,\n",
    "            device='cpu',\n",
    "            workers=1,\n",
    "            patience=50,\n",
    "            save=False,\n",
    "            plots=False,\n",
    "            verbose=True,  # Show some progress\n",
    "            cache=False,\n",
    "            close_mosaic=0,\n",
    "            project=str(project_root / \"runs\" / \"detect\"),\n",
    "            name=\"micro_test\",\n",
    "            exist_ok=True\n",
    "        )\n",
    "        \n",
    "        print(\"üéâ Micro-training completed!\")\n",
    "        print(\"‚úÖ Your setup works for training!\")\n",
    "        \n",
    "        # Show results if available\n",
    "        if hasattr(results, 'box') and hasattr(results.box, 'map50'):\n",
    "            print(f\"üìä mAP@0.5: {results.box.map50:.3f}\")\n",
    "        \n",
    "        # Clean up\n",
    "        del model, results\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Micro-training failed: {e}\")\n",
    "        print(\"üí° This might be normal - your M2 Air might need even lighter settings\")\n",
    "        \n",
    "        # Try even more minimal fallback\n",
    "        print(\"\\nüîß Trying validation-only test...\")\n",
    "        try:\n",
    "            model = YOLO('yolo11n.pt')\n",
    "            val_results = model.val(\n",
    "                data=\"VisDrone.yaml\",\n",
    "                imgsz=160,\n",
    "                batch=1,\n",
    "                device='cpu',\n",
    "                verbose=False\n",
    "            )\n",
    "            print(\"‚úÖ Validation test worked!\")\n",
    "            del model, val_results\n",
    "            gc.collect()\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Even validation failed: {e2}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping micro-training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edf4de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã RESULTS AND RECOMMENDATIONS\n",
      "==================================================\n",
      "‚úÖ Some training results found:\n",
      "   üìÅ skyguard_drone_detection_quick_test\n",
      "   üìÅ train2\n",
      "   üìÅ train3\n",
      "\n",
      "üéØ RECOMMENDATIONS FOR M2 AIR 8GB:\n",
      "1. üíæ Use swap space: System Preferences > Memory\n",
      "2. üîß Optimal settings for your hardware:\n",
      "   yolo detect train data=VisDrone.yaml model=yolo11n.pt \\\n",
      "     epochs=20 imgsz=320 batch=2 device=cpu workers=2 \\\n",
      "     patience=5 cache=False plots=False\n",
      "\n",
      "3. ‚ö° For fastest testing:\n",
      "   yolo detect val model=yolo11n.pt data=VisDrone.yaml imgsz=320 batch=1\n",
      "\n",
      "4. üéÆ If training is too slow, focus on:\n",
      "   ‚Ä¢ Data exploration and validation\n",
      "   ‚Ä¢ Model inference testing\n",
      "   ‚Ä¢ Deployment preparation\n",
      "   ‚Ä¢ Use cloud training for heavy work\n",
      "\n",
      "üéâ Testing complete!\n",
      "üí° Your M2 Air can handle the project - just needs optimized settings!\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Results and Recommendations\n",
    "print(\"\\nüìã RESULTS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if any training results exist\n",
    "runs_dir = project_root / \"runs\" / \"detect\"\n",
    "if runs_dir.exists() and any(runs_dir.iterdir()):\n",
    "    print(\"‚úÖ Some training results found:\")\n",
    "    for run_dir in sorted(runs_dir.iterdir(), key=lambda x: x.stat().st_mtime, reverse=True)[:3]:\n",
    "        if run_dir.is_dir():\n",
    "            print(f\"   üìÅ {run_dir.name}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No training results yet\")\n",
    "\n",
    "print(\"\\nüéØ RECOMMENDATIONS FOR M2 AIR 8GB:\")\n",
    "print(\"1. üíæ Use swap space: System Preferences > Memory\")\n",
    "print(\"2. üîß Optimal settings for your hardware:\")\n",
    "print(\"   yolo detect train data=VisDrone.yaml model=yolo11n.pt \\\\\")\n",
    "print(\"     epochs=20 imgsz=320 batch=2 device=cpu workers=2 \\\\\")\n",
    "print(\"     patience=5 cache=False plots=False\")\n",
    "print()\n",
    "print(\"3. ‚ö° For fastest testing:\")\n",
    "print(\"   yolo detect val model=yolo11n.pt data=VisDrone.yaml imgsz=320 batch=1\")\n",
    "print()\n",
    "print(\"4. üéÆ If training is too slow, focus on:\")\n",
    "print(\"   ‚Ä¢ Data exploration and validation\")\n",
    "print(\"   ‚Ä¢ Model inference testing\")\n",
    "print(\"   ‚Ä¢ Deployment preparation\")\n",
    "print(\"   ‚Ä¢ Use cloud training for heavy work\")\n",
    "\n",
    "print(\"\\nüéâ Testing complete!\")\n",
    "print(\"üí° Your M2 Air can handle the project - just needs optimized settings!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f5d4863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ QUICK SUCCESS CHECK\n",
      "==================================================\n",
      "üéØ SUCCESS ITEMS (4/4):\n",
      "   ‚úÖ YOLO installation works\n",
      "   ‚úÖ VisDrone data found\n",
      "   ‚úÖ Processed YOLO dataset ready\n",
      "   ‚úÖ Training capability confirmed\n",
      "\n",
      "üéâ You have a functional setup!\n",
      "üöÄ Ready to proceed with optimized training or move to next phase\n",
      "\n",
      "üîö Notebook complete! Run cells individually to debug any issues.\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Quick Success Validation\n",
    "print(\"\\n‚úÖ QUICK SUCCESS CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "success_items = []\n",
    "\n",
    "# Check 1: YOLO installation\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    YOLO('yolo11n.pt')\n",
    "    success_items.append(\"YOLO installation works\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Check 2: Data exists\n",
    "if (project_root / \"data\" / \"raw\" / \"vision\" / \"visdrone\").exists():\n",
    "    success_items.append(\"VisDrone data found\")\n",
    "\n",
    "# Check 3: Processed data\n",
    "if dataset_yaml.exists():\n",
    "    success_items.append(\"Processed YOLO dataset ready\")\n",
    "\n",
    "# Check 4: Training capability\n",
    "if runs_dir.exists() and any(runs_dir.iterdir()):\n",
    "    success_items.append(\"Training capability confirmed\")\n",
    "\n",
    "print(f\"üéØ SUCCESS ITEMS ({len(success_items)}/4):\")\n",
    "for item in success_items:\n",
    "    print(f\"   ‚úÖ {item}\")\n",
    "\n",
    "if len(success_items) >= 2:\n",
    "    print(\"\\nüéâ You have a functional setup!\")\n",
    "    print(\"üöÄ Ready to proceed with optimized training or move to next phase\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some setup issues remain\")\n",
    "    print(\"üí° Focus on getting basic YOLO working first\")\n",
    "\n",
    "print(\"\\nüîö Notebook complete! Run cells individually to debug any issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf06ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skyguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
